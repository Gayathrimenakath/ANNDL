{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VespX1d2iNG4"
      },
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yvui3US7Y5W1"
      },
      "source": [
        "import numpy as np \n",
        "import os\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import numpy as np\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0SqYhpNJ9gb"
      },
      "source": [
        "import os\n",
        "\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Set the seed for random operations. \n",
        "# This let our experiments to be reproducible. \n",
        "SEED = 1234\n",
        "tf.random.set_seed(SEED) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpsLdgk_J_9P"
      },
      "source": [
        "cwd = os.getcwd()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-eMtZgCKB2R",
        "outputId": "3d8a69f8-bef7-493f-d3cb-b623a3aa2490"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKszpTSvKFJE"
      },
      "source": [
        "#!unzip /content/drive/My\\ Drive/Development_Dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTbkc6TkKHJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4b41e33-03e1-49b6-a6ab-65b813c7dcb3"
      },
      "source": [
        "!ls /content/Development_Dataset/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LICENSE.txt  Test_Dev  Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk3VpcHxKJpK"
      },
      "source": [
        "# ImageDataGenerator\n",
        "# ------------------\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "input_dir = True\n",
        "\n",
        "# Create training ImageDataGenerator object\n",
        "# We need two different generators for images and corresponding masks\n",
        "if input_dir:\n",
        "  inp_img_data_gen = ImageDataGenerator(validation_split =0.2)\n",
        "  inp_mask_data_gen = ImageDataGenerator(validation_split =0.2,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOZHtojxKNhx"
      },
      "source": [
        "apply_data_augmentation = True\n",
        "if apply_data_augmentation:\n",
        "    img_data_gen = ImageDataGenerator(rotation_range=10,\n",
        "                                      width_shift_range=10,\n",
        "                                      height_shift_range=10,\n",
        "                                      zoom_range=0.3,\n",
        "                                      horizontal_flip=True,\n",
        "                                      vertical_flip=True,\n",
        "                                      fill_mode='reflect')\n",
        "    mask_data_gen = ImageDataGenerator(rotation_range=10,\n",
        "                                       width_shift_range=10,\n",
        "                                       height_shift_range=10,\n",
        "                                       zoom_range=0.3,\n",
        "                                       horizontal_flip=True,\n",
        "                                       vertical_flip=True,\n",
        "                                       fill_mode='reflect')\n",
        "    \n",
        "test_img_data_gen = ImageDataGenerator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6o9bMvrKPs1"
      },
      "source": [
        "# Create generators to read images from dataset directory\n",
        "# -------------------------------------------------------\n",
        "dataset_dir = os.path.join(cwd, 'Development_Dataset')\n",
        "\n",
        "# img\n",
        "\n",
        "# Batch size\n",
        "bs = 16\n",
        "\n",
        "# img shape\n",
        "img_h = 256\n",
        "img_w = 256\n",
        "\n",
        "\n",
        "# Training\n",
        "img_training_dir = os.path.join(dataset_dir, 'Training/Bipbip/Haricot/')\n",
        "train_img_gen = inp_img_data_gen.flow_from_directory(img_training_dir,\n",
        "                                                       classes = ['Images'],\n",
        "                                               target_size=(img_h, img_w),\n",
        "                                                       batch_size=bs,\n",
        "                                                       class_mode=None, \n",
        "                                                     interpolation='bilinear',\n",
        "                                                       shuffle=True,\n",
        "                                                       \n",
        "                                                       seed=SEED,\n",
        "                                                       subset='training')  # targets are directly converted into one-hot vectors\n",
        "mask_training_dir = os.path.join(dataset_dir, 'Training/Bipbip/Haricot/')\n",
        "train_mask_gen = inp_mask_data_gen.flow_from_directory(mask_training_dir,\n",
        "                                               classes = ['Masks'],\n",
        "                                               batch_size=bs, \n",
        "                                               class_mode=None,\n",
        "                                               interpolation='bilinear',\n",
        "                                               shuffle=True,\n",
        "                                               seed=SEED,\n",
        "                                               subset='training')  # targets are directly converted into one-hot vectors\n",
        "train_gen = zip(train_img_gen, train_mask_gen)\n",
        "\n",
        "valid_img_gen = inp_img_data_gen.flow_from_directory(img_training_dir,\n",
        "                                                  classes = ['Images'],\n",
        "                                                  target_size=(img_h, img_w),\n",
        "                                                       batch_size=bs,\n",
        "                                                       class_mode=None, \n",
        "                                                     interpolation='bilinear',\n",
        "                                                       shuffle=False,\n",
        "                                                       \n",
        "                                                       seed=SEED,\n",
        "                                                  subset='validation')\n",
        "valid_mask_gen = inp_mask_data_gen.flow_from_directory(mask_training_dir,\n",
        "                                                  classes = ['Masks'],\n",
        "                                                  target_size=(img_h, img_w),\n",
        "                                                  interpolation='bilinear',\n",
        "                                                       batch_size=bs,\n",
        "                                                       class_mode=None, \n",
        "                                                       shuffle=False,\n",
        "                                                      \n",
        "                                                       seed=SEED,\n",
        "                                                  subset='validation')\n",
        "valid_gen = zip(valid_img_gen, valid_mask_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuhNITjKKyUY"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "class CustomDataset(tf.keras.utils.Sequence):\n",
        "\n",
        "  \"\"\"\n",
        "    CustomDataset inheriting from tf.keras.utils.Sequence.\n",
        "\n",
        "    3 main methods:\n",
        "      - __init__: save dataset params like directory, filenames..\n",
        "      - __len__: return the total number of samples in the dataset\n",
        "      - __getitem__: return a sample from the dataset\n",
        "\n",
        "    Note: \n",
        "      - the custom dataset return a single sample from the dataset. Then, we use \n",
        "        a tf.data.Dataset object to group samples into batches.\n",
        "      - in this case we have a different structure of the dataset in memory. \n",
        "        We have all the images in the same folder and the training and validation splits\n",
        "        are defined in text files.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, dataset_dir, which_subset, gen, img_generator=None, mask_generator=None, \n",
        "               preprocessing_function=None, out_shape=[256, 256]):\n",
        "    \n",
        "    self.which_subset = which_subset\n",
        "    self.dataset_dir = dataset_dir\n",
        "    self.img_generator = img_generator\n",
        "    self.mask_generator = mask_generator\n",
        "    self.preprocessing_function = preprocessing_function\n",
        "    self.out_shape = out_shape\n",
        "    self.gen = gen\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.gen.filenames)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # Read Image\n",
        "    c = self.gen.filenames[index]\n",
        "    c1 = c.split('/')\n",
        "    c2 = c1[1].split('.')\n",
        "    curr_filename = c2[0]\n",
        "    if self.which_subset == 'training':\n",
        "      img = Image.open(os.path.join(self.dataset_dir, 'Training/Bipbip/Haricot/Images', curr_filename + '.jpg'))\n",
        "      mask = Image.open(os.path.join(self.dataset_dir, 'Training/Bipbip/Haricot/Masks', curr_filename + '.png'))\n",
        "    else:\n",
        "      img = Image.open(os.path.join(self.dataset_dir, 'Training/Bipbip/Haricot/Images', curr_filename + '.jpg'))\n",
        "      mask = Image.open(os.path.join(self.dataset_dir, 'Training/Bipbip/Haricot/Masks', curr_filename + '.png'))\n",
        "\n",
        "   # Resize image and mask\n",
        "    img = img.resize(self.out_shape)\n",
        "    mask = mask.resize(self.out_shape, resample=Image.NEAREST)\n",
        "    \n",
        "    img_arr = np.array(img)\n",
        "    mask_arr = np.array(mask)\n",
        "\n",
        "    new_mask_arr = np.zeros(mask_arr.shape[:2], dtype=mask_arr.dtype)\n",
        "    new_mask_arr[np.where(np.all(mask_arr == [254, 124, 18], axis=-1))] = 0\n",
        "    new_mask_arr[np.where(np.all(mask_arr == [0, 0, 0], axis=-1))] = 0\n",
        "    new_mask_arr[np.where(np.all(mask_arr == [255, 255, 255], axis=-1))] = 1\n",
        "    new_mask_arr[np.where(np.all(mask_arr == [216, 67, 82], axis=-1))] = 2\n",
        "    \n",
        "    new_mask_arr = np.expand_dims(new_mask_arr, -1)\n",
        "\n",
        "\n",
        "    if self.which_subset == 'training':\n",
        "      if self.img_generator is not None and self.mask_generator is not None:\n",
        "        # Perform data augmentation\n",
        "        # We can get a random transformation from the ImageDataGenerator using get_random_transform\n",
        "        # and we can apply it to the image using apply_transform\n",
        "        img_t = self.img_generator.get_random_transform(img_arr.shape, seed=SEED)\n",
        "        mask_t = self.mask_generator.get_random_transform(new_mask_arr.shape, seed=SEED)\n",
        "        img_arr = self.img_generator.apply_transform(img_arr, img_t)\n",
        "\n",
        "        out_mask = np.zeros_like(new_mask_arr)\n",
        "        for c in np.unique(new_mask_arr):\n",
        "          if c > 0:\n",
        "            curr_class_arr = np.float32(new_mask_arr == c)\n",
        "            curr_class_arr = self.mask_generator.apply_transform(curr_class_arr, mask_t)\n",
        "            # from [0, 1] to {0, 1}\n",
        "            curr_class_arr = np.uint8(curr_class_arr)\n",
        "            # recover original class\n",
        "            curr_class_arr = curr_class_arr * c \n",
        "            out_mask += curr_class_arr\n",
        "    else:\n",
        "      out_mask = new_mask_arr\n",
        "    \n",
        "    if self.preprocessing_function is not None:\n",
        "        img_arr = self.preprocessing_function(img_arr)\n",
        "\n",
        "    return img_arr, np.float32(out_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzkdwKsLO0B1"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import preprocess_input \n",
        "\n",
        "img_h = 256\n",
        "img_w = 256\n",
        "\n",
        "dataset = CustomDataset('/content/Development_Dataset/', 'training', gen = train_img_gen,\n",
        "                        img_generator=img_data_gen, mask_generator=mask_data_gen,\n",
        "                        preprocessing_function=preprocess_input)\n",
        "dataset_valid = CustomDataset('/content/Development_Dataset', 'validation', gen = valid_img_gen,\n",
        "                              preprocessing_function=preprocess_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5oEDpT7O3Bg"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_generator(lambda: dataset,\n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=([img_h, img_w, 3], [img_h, img_w, 1]))\n",
        "\n",
        "\n",
        "train_dataset = train_dataset.batch(32)\n",
        "\n",
        "train_dataset = train_dataset.repeat()\n",
        "\n",
        "valid_dataset = tf.data.Dataset.from_generator(lambda: dataset_valid,\n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=([img_h, img_w, 3], [img_h, img_w, 1]))\n",
        "\n",
        "valid_dataset = valid_dataset.batch(32)\n",
        "\n",
        "valid_dataset = valid_dataset.repeat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vptI9YcpO5Xf"
      },
      "source": [
        "# Let's test data generator\n",
        "# -------------------------\n",
        "import time\n",
        "from matplotlib import cm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "iterator = iter(train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rn3jdc5O7xJ"
      },
      "source": [
        "fig, ax = plt.subplots(1, 2)\n",
        "\n",
        "augmented_img, target = next(iterator)\n",
        "augmented_img = augmented_img[0]   # First element\n",
        "augmented_img = augmented_img  # denormalize\n",
        "\n",
        "target = np.array(target[0, ..., 0])   # First element (squeezing channel dimension)\n",
        "\n",
        "print(np.unique(target))\n",
        "\n",
        "target_img = np.zeros([target.shape[0], target.shape[1], 3])\n",
        "\n",
        "target_img[np.where(target == 0)] = [0, 0, 0]\n",
        "target_img[np.where(target == 1)] = [255, 255, 255]\n",
        "target_img[np.where(target == 2)] = [0, 255, 0]\n",
        "# target_img[np.where(target == 3)] = [255, 0, 0]\n",
        "\n",
        "ax[0].imshow(np.uint8(augmented_img))\n",
        "ax[1].imshow(np.uint8(target_img))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlksE-GU9L3x"
      },
      "source": [
        "def meanIoU(y_true, y_pred):\n",
        "    # get predicted class from softmax\n",
        "    y_pred = tf.expand_dims(tf.argmax(y_pred, -1), -1)\n",
        "\n",
        "    per_class_iou = []\n",
        "\n",
        "    for i in range(1,2): # exclude the background class 0\n",
        "      # Get prediction and target related to only a single class (i)\n",
        "      class_pred = tf.cast(tf.where(y_pred == i, 1, 0), tf.float32)\n",
        "      class_true = tf.cast(tf.where(y_true == i, 1, 0), tf.float32)\n",
        "      intersection = tf.reduce_sum(class_true * class_pred)\n",
        "      union = tf.reduce_sum(class_true) + tf.reduce_sum(class_pred) - intersection\n",
        "    \n",
        "      iou = (intersection + 1e-7) / (union + 1e-7)\n",
        "      per_class_iou.append(iou)\n",
        "\n",
        "    return tf.reduce_mean(per_class_iou)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h2iuG6N257g"
      },
      "source": [
        "def create_model(img_size,num_classes):\n",
        "    inputs = tf.keras.Input(shape=img_size +(3,))\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "    model = tf.keras.Model(inputs, conv10)\n",
        "\n",
        "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics=[meanIoU])\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJo4CJWhPDNw"
      },
      "source": [
        "img_size=(256,256)\n",
        "model = create_model(img_size,num_classes=3)\n",
        "\n",
        "# Visualize created model as a table\n",
        "model.summary()\n",
        "\n",
        "# Visualize initialized weights\n",
        "# model.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYbafMV3PIPw"
      },
      "source": [
        "# Optimization params\n",
        "# -------------------\n",
        "\n",
        "# Loss\n",
        "# Sparse Categorical Crossentropy to use integers (mask) instead of one-hot encoded labels\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy() \n",
        "# learning rate\n",
        "lr = 1e-3\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "# -------------------\n",
        "\n",
        "# ------------------\n",
        "metrics = ['accuracy', meanIoU]\n",
        "# ------------------\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtP2GC5DPIsx"
      },
      "source": [
        "import os\n",
        "from datetime import datetime \n",
        "callbacks = []\n",
        "\n",
        "# Early Stopping\n",
        "# --------------\n",
        "early_stop = True\n",
        "if early_stop:\n",
        "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "    callbacks.append(es_callback)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nLwsAVMPLA-"
      },
      "source": [
        "model.fit(x=train_dataset,\n",
        "          epochs=3,  #### set repeat in training dataset\n",
        "          steps_per_epoch=len(dataset),\n",
        "          validation_data=valid_dataset,\n",
        "          validation_steps=len(dataset_valid), \n",
        "          callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFOPcXKqFe6v"
      },
      "source": [
        "#Preparing submission.json file\n",
        "from keras.preprocessing.image import save_img\n",
        "def submit(submission_dict,team,crop):\n",
        "    path_mask='Development_Dataset/Test_Dev/Bipbip/Haricot/Masks'\n",
        "    if not os.path.exists(path_mask):\n",
        "      os.mkdir(path_mask)\n",
        "    path =\"Development_Dataset/Test_Dev/\"\n",
        "    dir= os.path.join(path,team,crop,'Images')\n",
        "    predicted_images =next(os.walk(dir))[2]\n",
        "    print (type(predicted_images))\n",
        "    for img in predicted_images:\n",
        "      mask_img = img.split(\".\")\n",
        "      mask_img=mask_img[0]\n",
        "      test_image = Image.open(os.path.join(dir,img))\n",
        "\n",
        "      size=(256,256)\n",
        "      test_image = test_image.resize(size)\n",
        "      tf_test_image = tf.convert_to_tensor(\n",
        "      np.array(test_image), dtype='float32'\n",
        "      )\n",
        "      out_sigmoid = model.predict(x=tf.expand_dims(tf_test_image, 0))\n",
        "      predicted_class = tf.argmax(out_sigmoid, -1)\n",
        "      predicted_class = predicted_class[0, ...]\n",
        "\n",
        "      prediction_img = np.zeros([tf_test_image.shape[0], tf_test_image.shape[1], 3])\n",
        "      prediction_img[np.where(predicted_class == 0)] = [0, 0, 0]\n",
        "      prediction_img[np.where(predicted_class == 1)] = [255, 255, 255]\n",
        "      prediction_img[np.where(predicted_class == 2)] = [216, 67, 82]\n",
        "\n",
        "      #saving mask images to a new folder\n",
        "      save_img('Development_Dataset/Test_Dev/Bipbip/Haricot/Masks/' + mask_img + '.png',prediction_img)\n",
        "\n",
        "      mask_arr=read_rgb_mask(\"Development_Dataset/Test_Dev/Bipbip/Haricot/Masks/\" + mask_img + '.png')\n",
        "\n",
        "      submission_dict[mask_img] = {}\n",
        "      submission_dict[mask_img]['shape'] = mask_arr.shape\n",
        "      submission_dict[mask_img]['team'] = team\n",
        "      submission_dict[mask_img]['crop'] = crop\n",
        "      submission_dict[mask_img]['segmentation'] = {}\n",
        "\n",
        "      # RLE encoding\n",
        "      # crop\n",
        "      rle_encoded_crop = rle_encode(mask_arr == 1)\n",
        "      # weed\n",
        "      rle_encoded_weed = rle_encode(mask_arr == 2)\n",
        "\n",
        "      submission_dict[mask_img]['segmentation']['crop'] = rle_encoded_crop\n",
        "      submission_dict[mask_img]['segmentation']['weed'] = rle_encoded_weed\n",
        "      print(submission_dict)\n",
        "    return submission_dict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06IRiacXFnNZ"
      },
      "source": [
        "#reading rgb masks\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def read_rgb_mask(img_path):\n",
        "    '''\n",
        "    img_path: path to the mask file\n",
        "    Returns the numpy array containing target values\n",
        "    '''\n",
        "\n",
        "    mask_img = Image.open(img_path)\n",
        "    mask_arr = np.array(mask_img)\n",
        "\n",
        "    new_mask_arr = np.zeros(mask_arr.shape[:2], dtype=mask_arr.dtype)\n",
        "\n",
        "    # Use RGB dictionary in 'RGBtoTarget.txt' to convert RGB to target\n",
        "    new_mask_arr[np.where(np.all(mask_arr == [255, 255, 255], axis=-1))] = 1\n",
        "    new_mask_arr[np.where(np.all(mask_arr == [216, 67, 82], axis=-1))] = 2\n",
        "\n",
        "    return new_mask_arr\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BhP8xniFnxC"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def rle_encode(img):\n",
        "    '''\n",
        "    img: numpy array, 1 - foreground, 0 - background\n",
        "    Returns run length as string formatted\n",
        "    '''\n",
        "    pixels = img.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_qzuC33FqBG"
      },
      "source": [
        "#def submission():\n",
        "submission_dict = {}\n",
        "\n",
        "submission_dict = submit(submission_dict,'Bipbip','Haricot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3zcO5vzIUFn"
      },
      "source": [
        "with open('submission.json', 'w') as f:\n",
        "  json.dump(submission_dict, f)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}