{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TransferLearning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLJKSuoKKhGL"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "SEED = 1234\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "cwd = os.getcwd()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZaG5oxhW_9J"
      },
      "source": [
        "## Mount Google Drive and unzip the dataset\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDfV3kCAKthR"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip '/content/gdrive/My Drive/Kaggle/artificial-neural-networks-and-deep-learning-2020.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6JdLMoCLkMt"
      },
      "source": [
        "ls /content/artificial-neural-networks-and-deep-learning-2020/MaskDataset/training/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKQo7ouuX4JW"
      },
      "source": [
        "## Load the json file with all the class labels for training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YANYenkkKwYT"
      },
      "source": [
        "import json\n",
        "with open('/content/artificial-neural-networks-and-deep-learning-2020/MaskDataset/train_gt.json', 'r') as f:\n",
        "  data = json.load(f)\n",
        "df = pd.DataFrame(list(data.items()), columns=['filename', 'category'])\n",
        "\n",
        "df = df.applymap(str)\n",
        "df.category.value_counts()\n",
        "filenames = [*data]\n",
        "#print(filenames)\n",
        "df.head()\n",
        "\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ1TvKHcccp6"
      },
      "source": [
        "## **Preprocessing - ImageDataGenerator**\n",
        "\n",
        "Apply data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtCeMTwlKwZ4"
      },
      "source": [
        "# ImageDataGenerator\n",
        "# ------------------\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "apply_data_augmentation = True\n",
        "\n",
        "# Create training ImageDataGenerator object\n",
        "if apply_data_augmentation:\n",
        "    train_data_gen = ImageDataGenerator(rotation_range=10,\n",
        "                                        width_shift_range=0.2,\n",
        "                                        height_shift_range=0.2,\n",
        "                                        zoom_range=0.3,\n",
        "                                        validation_split=0.15,\n",
        "                                        horizontal_flip=True,\n",
        "                                        vertical_flip=True,\n",
        "                                        fill_mode='constant',\n",
        "                                        cval=0,\n",
        "                                        rescale=1./255)\n",
        "else:\n",
        "    train_data_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create validation and test ImageDataGenerator objects\n",
        "valid_data_gen = ImageDataGenerator(rescale=1./255)\n",
        "test_data_gen = ImageDataGenerator(rescale=1./255)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgDaybolKweu"
      },
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "dataset_dir = os.path.join(cwd, 'MaskDatase')\n",
        "\n",
        "# img\n",
        "\n",
        "# Batch size\n",
        "bs = 128\n",
        "\n",
        "# img shape\n",
        "img_h = 32\n",
        "img_w = 32\n",
        "img_size=(32,32)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhOiXluDd2af"
      },
      "source": [
        "## Split dataset into train and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-NP1GU2ecxc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.25, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pac2MMxHdzGb"
      },
      "source": [
        "## Create generators to read images from dataset directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5idoHiJ3mJ6q"
      },
      "source": [
        "train_gen = train_data_gen.flow_from_dataframe(\n",
        "            train_df,\n",
        "            directory='/content/artificial-neural-networks-and-deep-learning-2020/MaskDataset/training',\n",
        "            x_col=\"filename\",\n",
        "            y_col=\"category\",\n",
        "            subset=\"training\",\n",
        "            batch_size=bs,\n",
        "            seed=42,\n",
        "            shuffle=True,\n",
        "            class_mode=\"categorical\",\n",
        "            target_size=img_size)\n",
        "valid_gen = train_data_gen.flow_from_dataframe(\n",
        "            train_df,\n",
        "            directory='/content/artificial-neural-networks-and-deep-learning-2020/MaskDataset/training',\n",
        "            x_col=\"filename\",\n",
        "            y_col=\"category\",\n",
        "            subset=\"validation\",\n",
        "            batch_size=bs,\n",
        "            seed=42,\n",
        "            shuffle=True,\n",
        "            class_mode=\"categorical\",\n",
        "            target_size=img_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuVkY5GFx9YP"
      },
      "source": [
        "# Create Dataset objects\n",
        "# ----------------------\n",
        "\n",
        "\n",
        "num_classes = 3\n",
        "# Training\n",
        "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n",
        "\n",
        "\n",
        "train_dataset = train_dataset.repeat()\n",
        "\n",
        "# Validation\n",
        "# ----------\n",
        "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n",
        "\n",
        "# Repeat\n",
        "valid_dataset = valid_dataset.repeat()\n",
        "\n",
        "# Test\n",
        "# ----\n",
        "test_dataset = tf.data.Dataset.from_generator(lambda: test_gen,\n",
        "                                              output_types=(tf.float32, tf.float32),\n",
        "                                              output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n",
        "\n",
        "# Repeat\n",
        "test_dataset = valid_dataset.repeat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbO4ySi7cv4Q"
      },
      "source": [
        "## Test data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZz1fVMg0ulw"
      },
      "source": [
        "# Let's test data augmentation\n",
        "# ----------------------------\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "    \n",
        "iterator = iter(train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtPkRJ2I0zby"
      },
      "source": [
        "augmented_img, target = next(iterator)\n",
        "augmented_img = np.array(augmented_img[0])   # First element\n",
        "augmented_img = augmented_img * 255  # denormalize\n",
        "   \n",
        "plt.imshow(np.uint8(augmented_img))\n",
        "# fig.canvas.draw()\n",
        "plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxvXWgAU0_IP"
      },
      "source": [
        "## **CNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtgGANgQ08et"
      },
      "source": [
        "train_gen.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_MEA_cGXtMM"
      },
      "source": [
        "##**Transfer learning**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JItwP6iM1kJq"
      },
      "source": [
        "# Create Model\n",
        "# ------------\n",
        "# Load VGG16 Model\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "\n",
        "\n",
        "densenet = tf.keras.applications.DenseNet201(weights='imagenet',include_top=False, input_shape=(img_h, img_w, 3))\n",
        "finetuning = True\n",
        "\n",
        "if finetuning:\n",
        "    freeze_until = 15 # layer from which we want to fine-tune\n",
        "    \n",
        "    for layer in densenet.layers[:freeze_until]:\n",
        "        layer.trainable = False\n",
        "else:\n",
        "    densenet.trainable = False\n",
        "    \n",
        "model = tf.keras.Sequential()\n",
        "model.add(densenet)\n",
        "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Mz1W5bg3buA"
      },
      "source": [
        "# Visualize created model as a table\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUzBwNSiZMP7"
      },
      "source": [
        "## Prepare the model for training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foGaWVO44xxf"
      },
      "source": [
        "# Optimization params\n",
        "# -------------------\n",
        "\n",
        "# Loss\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "# learning rate\n",
        "lr = 0.0001\n",
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
        "# -------------------\n",
        "\n",
        "# Validation metrics\n",
        "# ------------------\n",
        "\n",
        "metrics = ['accuracy']\n",
        "# ------------------\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2B5SvadZioN"
      },
      "source": [
        "## Training with callbacks\n",
        "\n",
        "Added ReduceLROnPlateau to reduce the learning rate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiyTM8j46s5m"
      },
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "cwd = os.getcwd()\n",
        "\n",
        "exps_dir = os.path.join('content/drive/My Drive/Keras3/', 'classification_experiments')\n",
        "if not os.path.exists(exps_dir):\n",
        "    os.makedirs(exps_dir)\n",
        "\n",
        "now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
        "\n",
        "model_name = 'CNN'\n",
        "\n",
        "exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
        "if not os.path.exists(exp_dir):\n",
        "    os.makedirs(exp_dir)\n",
        "    \n",
        "callbacks = []\n",
        "\n",
        "# Model checkpoint\n",
        "# ----------------\n",
        "ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
        "if not os.path.exists(ckpt_dir):\n",
        "    os.makedirs(ckpt_dir)\n",
        "\n",
        "\n",
        "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'), \n",
        "                                                   monitor='val_loss', verbose=1, save_best_only=True, mode='min',\n",
        "                                                   save_weights_only=True)  # False to save the model directly\n",
        "\n",
        "callbacks.append(ckpt_callback)\n",
        "\n",
        "# Visualize Learning on Tensorboard\n",
        "# ---------------------------------\n",
        "tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
        "if not os.path.exists(tb_dir):\n",
        "    os.makedirs(tb_dir)\n",
        "    \n",
        "# By default shows losses and metrics for both training and validation\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
        "                                             profile_batch=0,\n",
        "                                             histogram_freq=1)  # if 1 shows weights histograms\n",
        "callbacks.append(tb_callback)\n",
        "\n",
        "# Early Stopping\n",
        "# --------------\n",
        "early_stop = True\n",
        "if early_stop:\n",
        "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "    callbacks.append(es_callback)\n",
        "\n",
        "reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=10, verbose=1, mode='max')\n",
        "callbacks.append(reduce_lr_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaIEApQaZwmT"
      },
      "source": [
        "## Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soXo3yOMBmYk"
      },
      "source": [
        "model.fit(x=train_dataset,\n",
        "          epochs=100,  #### set repeat in training dataset\n",
        "          steps_per_epoch=len(train_gen),\n",
        "          validation_data=valid_dataset,\n",
        "          validation_steps=len(valid_gen), \n",
        "          callbacks=(callbacks))\n",
        "\n",
        "# 1. tensorboard --logdir EXPERIMENTS_DIR --port PORT     <- from terminal\n",
        "# 2. localhost:PORT   <- in your browser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUsTRYDAZ2Ii"
      },
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J1wy27am_Fx"
      },
      "source": [
        "model.load_weights('/content/drive/MyDrive/Keras3/transfer_learning_experiments/CNN_Nov21_22-58-17/ckpts') \n",
        "\n",
        "\n",
        "eval_out = model.evaluate(x=test_dataset,\n",
        "                          steps=len(test_gen),\n",
        "                          verbose=0)\n",
        "eval_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae3fekPSaAGi"
      },
      "source": [
        "## Test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdYVCwPHqfSL"
      },
      "source": [
        " test_files_df=pd.DataFrame()\n",
        " test_files_df['file']=os.listdir('/content/artificial-neural-networks-and-deep-learning-2020/MaskDataset/test')\n",
        "print(\"Loaded test files list\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxM77fyvaEsE"
      },
      "source": [
        "## Generate output file for submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GipFxPIqXln"
      },
      "source": [
        "generator=ImageDataGenerator(rescale=1./255.).flow_from_dataframe(\n",
        "                    dataframe=test_files_df,\n",
        "                    directory=\"/content/artificial-neural-networks-and-deep-learning-2020/MaskDataset/test/\",\n",
        "                    x_col=\"file\",\n",
        "                    y_col=None,\n",
        "                    class_mode=None,\n",
        "                    batch_size=bs,\n",
        "                    seed=42,\n",
        "                    shuffle=False,\n",
        "                    target_size=img_size)    \n",
        "print('Submission generator created')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP41bQc2s2L-"
      },
      "source": [
        "print(\"Forming submission dataframe...\")\n",
        "y_pred = model.predict_generator(generator)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "# Create submission df\n",
        "submission_df = pd.DataFrame({\n",
        "    'Id':generator.filenames,\n",
        "    'Category':y_pred })\n",
        "#submission_df['filename'] = submission_df['filename'].apply(lambda x: x.split('.')[0])\n",
        "print(f\"Submission dataframe created. Rows:{len(submission_df.values)}\")\n",
        "  \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNEguBrJuDsn"
      },
      "source": [
        "submission_df.to_csv('submission.csv',index=False)\n",
        "print(\"Submission completed: written submission.csv\")  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}